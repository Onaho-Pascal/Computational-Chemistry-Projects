# from rdkit import Chem

# # Load the SDF file
# sdf_file = "JH_FK_35604094 (3).sdf"

# # Read the molecules
# supplier = Chem.SDMolSupplier(sdf_file)

# # Loop through and print SMILES
# for mol in supplier:
#     if mol is not None:
#         smiles = Chem.MolToSmiles(mol)
#         print(smiles)

# from chembl_webresource_client.new_client import new_client
# import pandas as pd
# import requests
# import os
# from tqdm import tqdm

# # ===============================
# # CONFIGURATION
# # ===============================
# # ===============================
# # CONFIGURATION
# # ===============================
# QUERY_SMILES = "C=CCOc1ccc(C2C(=C(O)c3ccc(OCc4cccc(C)c4)cc3)C(=O)C(=O)N2CCN(C)C)cc1"

# # Canonicalize the SMILES before querying
# from rdkit import Chem
# mol = Chem.MolFromSmiles(QUERY_SMILES)
# canonical_smiles = Chem.MolToSmiles(mol, canonical=True)
# QUERY_SMILES = canonical_smiles  # overwrite with canonical form

# IMAGE_DIR = "chembl_images3"
# OUT_FILE = "chembl_full_results3.csv"
# os.makedirs(IMAGE_DIR, exist_ok=True)

# print(f"‚úÖ Canonical SMILES: {QUERY_SMILES}")
# print("\nüîç Searching ChEMBL for similar and substructure compounds...")


# # ===============================
# # STEP 1: SEARCH COMPOUNDS
# # ===============================
# similarity_search = new_client.similarity
# substructure_search = new_client.substructure

# # similarity > 70% Tanimoto
# similar_hits = similarity_search.filter(smiles=QUERY_SMILES, similarity=40).only(
#     ["molecule_chembl_id", "pref_name", "molecule_type", "canonical_smiles"]
# )

# # substructure search
# substructure_hits = substructure_search.filter(smiles=QUERY_SMILES).only(
#     ["molecule_chembl_id", "pref_name", "molecule_type", "canonical_smiles"]
# )

# results = list(similar_hits) + list(substructure_hits)
# if not results:
#     print("‚ùå No results found in ChEMBL.")
#     exit()

# df = pd.DataFrame(results).drop_duplicates(subset=["molecule_chembl_id"])
# print(f"‚úÖ Retrieved {len(df)} unique compounds.")

# # ===============================
# # STEP 2: DOWNLOAD IMAGES
# # ===============================
# print("\nüß© Downloading 2D structure images...")
# for chembl_id in tqdm(df["molecule_chembl_id"], desc="Downloading images"):
#     img_url = f"https://www.ebi.ac.uk/chembl/api/data/image/{chembl_id}.svg"
#     img_path = os.path.join(IMAGE_DIR, f"{chembl_id}.svg")
#     try:
#         r = requests.get(img_url, timeout=10)
#         if r.status_code == 200:
#             with open(img_path, "wb") as f:
#                 f.write(r.content)
#         else:
#             pass  # skip failed downloads
#     except Exception:
#         pass

# # ===============================
# # STEP 3: FETCH BIOACTIVITY DATA
# # ===============================
# print("\nüß™ Fetching bioactivity data (IC50, Ki, etc.)...")
# bioactivity = new_client.activity

# bio_data = []
# for chembl_id in tqdm(df["molecule_chembl_id"], desc="Fetching bioactivity"):
#     acts = bioactivity.filter(molecule_chembl_id=chembl_id).only(
#         ["standard_type", "standard_value", "standard_units", "target_chembl_id", "target_pref_name"]
#     )
#     for a in acts:
#         a["molecule_chembl_id"] = chembl_id
#         bio_data.append(a)

# if bio_data:
#     bio_df = pd.DataFrame(bio_data)
#     merged = pd.merge(df, bio_df, on="molecule_chembl_id", how="left")
# else:
#     merged = df
#     print("‚ö†Ô∏è No bioactivity data found for these molecules.")

# # ===============================
# # STEP 4: SAVE RESULTS
# # ===============================
# merged.to_csv(OUT_FILE, index=False)
# print(f"\nüíæ Full results (structures + bioactivity) saved to: {OUT_FILE}")
# print(f"üñºÔ∏è Images saved in folder: {IMAGE_DIR}/")


# # from rdkit import Chem
# # mol = Chem.MolFromSmiles("C=CCOc1ccc(C2C(=C(O)c3ccc(OCc4cccc(C)c4)cc3)C(=O)C(=O)N2CCN(C)C)cc1")
# # print(mol is not None)


# # from chembl_webresource_client.new_client import new_client

# # query = "C=CCOc1ccc(C2C(=C(O)c3ccc(OCc4cccc(C)c4)cc3)C(=O)C(=O)N2CCN(C)C)cc1"

# # similarity_search = new_client.similarity
# # results = similarity_search.filter(smiles=query, similarity=40).only(['molecule_chembl_id'])

# # print("Found hits:", len(list(results)))


# ===============================================
# MULTI-DATABASE MOLECULAR SEARCH PIPELINE
# ===============================================

from rdkit import Chem
from chembl_webresource_client.new_client import new_client
import pandas as pd
import requests
import os
from tqdm import tqdm

# ===============================
# CONFIGURATION
# ===============================
sdf_file = "JH_FK_35604094 (3).sdf"
IMAGE_DIR = "compound_images3"
OUT_FILE = "multi_db_results_full3.csv"
os.makedirs(IMAGE_DIR, exist_ok=True)

SIMILARITY_THRESHOLD = 40

# Extract SMILES from input SDF
supplier = Chem.SDMolSupplier(sdf_file)
query_smiles = None
for mol in supplier:
    if mol is not None:
        query_smiles = Chem.MolToSmiles(mol, canonical=True)
        break
print(f"‚úÖ Query SMILES: {query_smiles}")

# ==================================================
# 1Ô∏è‚É£ ChEMBL SEARCH
# ==================================================
print("\nüîç Searching ChEMBL...")
similarity_search = new_client.similarity
substructure_search = new_client.substructure

chembl_results = []
try:
    similar_hits = similarity_search.filter(smiles=query_smiles, similarity=SIMILARITY_THRESHOLD)
    substructure_hits = substructure_search.filter(smiles=query_smiles)
    chembl_results = list(similar_hits) + list(substructure_hits)
except Exception as e:
    print(f"‚ö†Ô∏è ChEMBL search failed: {e}")

chembl_df = pd.DataFrame(chembl_results)
if not chembl_df.empty and "molecule_chembl_id" in chembl_df.columns:
    chembl_df = chembl_df.drop_duplicates(subset=["molecule_chembl_id"])

chembl_df["source"] = "ChEMBL"
print(f"‚úÖ {len(chembl_df)} hits from ChEMBL.")


# ==================================================
# 2Ô∏è‚É£ PubChem SEARCH
# ==================================================
print("\nüß™ Searching PubChem...")
pubchem_df = pd.DataFrame()
try:
    sim_url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/similarity/smiles/{query_smiles}/cids/JSON?Threshold={SIMILARITY_THRESHOLD}"
    r = requests.get(sim_url, timeout=30)
    data = r.json()
    cids = data.get("IdentifierList", {}).get("CID", [])
    smiles_list = []
    for cid in tqdm(cids[:50], desc="Fetching PubChem structures"):
        s_url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/property/CanonicalSMILES,Title/JSON"
        resp = requests.get(s_url, timeout=10)
        if resp.status_code == 200:
            props = resp.json()["PropertyTable"]["Properties"][0]
            smiles_list.append({
                "pubchem_id": cid,
                "canonical_smiles": props.get("CanonicalSMILES", ""),
                "pref_name": props.get("Title", "")
            })
    pubchem_df = pd.DataFrame(smiles_list)
    pubchem_df["source"] = "PubChem"
except Exception as e:
    print(f"‚ö†Ô∏è PubChem search failed: {e}")
print(f"‚úÖ {len(pubchem_df)} hits from PubChem.")


# ==================================================
# 3Ô∏è‚É£ ZINC SEARCH
# ==================================================
print("\nüß© Searching ZINC...")
zinc_df = pd.DataFrame()
try:
    zinc_url = f"https://zinc22.docking.org/api/substances/similar?smiles={query_smiles}&threshold={SIMILARITY_THRESHOLD}"
    r = requests.get(zinc_url, timeout=20)
    if r.status_code == 200 and "ZINC" in r.text:
        lines = r.text.strip().split("\n")
        zinc_records = [{"zinc_id": line.split()[0]} for line in lines if line.startswith("ZINC")]
        zinc_df = pd.DataFrame(zinc_records)
        zinc_df["source"] = "ZINC"
except Exception as e:
    print(f"‚ö†Ô∏è ZINC search failed: {e}")
print(f"‚úÖ {len(zinc_df)} hits from ZINC.")


# ==================================================
# 4Ô∏è‚É£ BindingDB SEARCH
# ==================================================
print("\nüß¨ Searching BindingDB...")
bindingdb_df = pd.DataFrame()
try:
    url = f"https://www.bindingdb.org/bind/chemsearch/marvin/SDFdownload.jsp?smiles={query_smiles}"
    r = requests.get(url, timeout=20)
    if r.status_code == 200 and len(r.content) > 100:
        open("bindingdb_temp.sdf", "wb").write(r.content)
        supplier = Chem.SDMolSupplier("bindingdb_temp.sdf")
        smiles_list = []
        for mol in supplier:
            if mol:
                smiles_list.append({"canonical_smiles": Chem.MolToSmiles(mol), "source": "BindingDB"})
        bindingdb_df = pd.DataFrame(smiles_list)
except Exception as e:
    print(f"‚ö†Ô∏è BindingDB search failed: {e}")
print(f"‚úÖ {len(bindingdb_df)} hits from BindingDB.")


# ==================================================
# 5Ô∏è‚É£ DrugCentral SEARCH
# ==================================================
print("\nüíä Searching DrugCentral...")
drugcentral_df = pd.DataFrame()
try:
    url = f"https://drugcentral.org/api/smiles/{query_smiles}"
    r = requests.get(url, timeout=20)
    if r.status_code == 200:
        data = r.json()
        if data:
            drugcentral_df = pd.json_normalize(data)
            drugcentral_df["source"] = "DrugCentral"
except Exception as e:
    print(f"‚ö†Ô∏è DrugCentral search failed: {e}")
print(f"‚úÖ {len(drugcentral_df)} hits from DrugCentral.")


# ==================================================
# 6Ô∏è‚É£ PDB Ligand Search
# ==================================================
print("\nüß© Searching RCSB PDB...")
pdb_df = pd.DataFrame()
try:
    query = {
        "query": {
            "type": "terminal",
            "service": "chem-comp-similarity",
            "parameters": {"value": query_smiles, "type": "descriptor", "cutoff": SIMILARITY_THRESHOLD}
        },
        "return_type": "entry"
    }
    r = requests.post("https://search.rcsb.org/rcsbsearch/v2/query", json=query)
    if r.status_code == 200:
        results = r.json().get("result_set", [])
        pdb_df = pd.DataFrame([{"pdb_id": r["identifier"], "source": "PDB"} for r in results])
except Exception as e:
    print(f"‚ö†Ô∏è PDB search failed: {e}")
print(f"‚úÖ {len(pdb_df)} hits from PDB.")


# ==================================================
# 7Ô∏è‚É£ KEGG SEARCH
# ==================================================
print("\nüß´ Searching KEGG...")
kegg_df = pd.DataFrame()
try:
    url = f"https://rest.kegg.jp/find/compound/{query_smiles}"
    r = requests.get(url)
    if r.status_code == 200 and r.text.strip():
        entries = [{"kegg_id": line.split("\t")[0], "desc": line.split("\t")[1], "source": "KEGG"}
                   for line in r.text.strip().split("\n")]
        kegg_df = pd.DataFrame(entries)
except Exception as e:
    print(f"‚ö†Ô∏è KEGG search failed: {e}")
print(f"‚úÖ {len(kegg_df)} hits from KEGG.")


# ==================================================
# 8Ô∏è‚É£ NPASS Natural Products
# ==================================================
print("\nüåø Searching NPASS...")
npass_df = pd.DataFrame()
try:
    url = f"https://bidd.group/NPASS/api/api_search_similar.php?smiles={query_smiles}&threshold={SIMILARITY_THRESHOLD}"
    r = requests.get(url, timeout=30)
    if r.status_code == 200 and len(r.text) > 0:
        try:
            npass_df = pd.read_json(r.text)
            npass_df["source"] = "NPASS"
        except Exception:
            pass
except Exception as e:
    print(f"‚ö†Ô∏è NPASS search failed: {e}")
print(f"‚úÖ {len(npass_df)} hits from NPASS.")


# ==================================================
# 9Ô∏è‚É£ COCONUT Natural Products
# ==================================================
print("\nü•• Searching COCONUT...")
coconut_df = pd.DataFrame()
try:
    url = f"https://coconut.naturalproducts.net/api/v1/similarity?smiles={query_smiles}&threshold={SIMILARITY_THRESHOLD}"
    r = requests.get(url, timeout=30)
    if r.status_code == 200:
        coconut_df = pd.DataFrame(r.json())
        coconut_df["source"] = "COCONUT"
except Exception as e:
    print(f"‚ö†Ô∏è COCONUT search failed: {e}")
print(f"‚úÖ {len(coconut_df)} hits from COCONUT.")


# ==================================================
# üîü Combine all results
# ==================================================
all_results = pd.concat([
    chembl_df, pubchem_df, zinc_df, bindingdb_df,
    drugcentral_df, pdb_df, kegg_df, npass_df, coconut_df
], ignore_index=True, sort=False)

print(f"\nüìä Combined total: {len(all_results)} compounds from all databases.")
all_results.to_csv(OUT_FILE, index=False)
print(f"üíæ Results saved to: {OUT_FILE}")

print("\n‚úÖ Multi-database compound search complete.")
